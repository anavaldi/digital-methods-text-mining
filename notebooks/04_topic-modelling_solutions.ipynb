{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the basics of topic modelling. \n",
    "You'll learn how identify topics in documents using the tf-idf matrix and ML classifier.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend of symbols:\n",
    "\n",
    "- ü§ì: Tips\n",
    "\n",
    "- ü§ñüìù: Your turn\n",
    "\n",
    "- ‚ùì: Question\n",
    "\n",
    "- üí´: Extra exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Tf-idf matrix + ML classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll learn how to do topic modelling based on bag of words and ML classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Build tf-idf matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the news dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>media</th>\n",
       "      <th>corpus</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>The reindeer is the emblematic Christmas anima...</td>\n",
       "      <td>Weatherwatch: reindeer adapted to snow but not...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/dec/23/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>The European parliament is split over whether ...</td>\n",
       "      <td>European parliament split on declaring climate...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/nov/26/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Fisayo Soyombo was eating an evening snack in ...</td>\n",
       "      <td>‚ÄòClimate of fear‚Äô: Nigeria intensifies crackdo...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/nov/14/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>The European Union considers itself as a leade...</td>\n",
       "      <td>EU's soaring climate rhetoric not always match...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/dec/11/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Good morning, we‚Äôre now exactly two weeks out ...</td>\n",
       "      <td>Thursday briefing: Political climate too hot f...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/nov/28/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic         media                                             corpus  \\\n",
       "0  climatic  The Guardian  The reindeer is the emblematic Christmas anima...   \n",
       "1  climatic  The Guardian  The European parliament is split over whether ...   \n",
       "2  climatic  The Guardian  Fisayo Soyombo was eating an evening snack in ...   \n",
       "3  climatic  The Guardian  The European Union considers itself as a leade...   \n",
       "4  climatic  The Guardian  Good morning, we‚Äôre now exactly two weeks out ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Weatherwatch: reindeer adapted to snow but not...   \n",
       "1  European parliament split on declaring climate...   \n",
       "2  ‚ÄòClimate of fear‚Äô: Nigeria intensifies crackdo...   \n",
       "3  EU's soaring climate rhetoric not always match...   \n",
       "4  Thursday briefing: Political climate too hot f...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.theguardian.com/world/2019/dec/23/...  \n",
       "1  https://www.theguardian.com/world/2019/nov/26/...  \n",
       "2  https://www.theguardian.com/world/2019/nov/14/...  \n",
       "3  https://www.theguardian.com/world/2019/dec/11/...  \n",
       "4  https://www.theguardian.com/world/2019/nov/28/...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1634, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bbbbbbbbbbbbbbbbbbbbbbpsppspspspsps'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub('a', 'b', 'aaaaaaaaaaaaaaaaaaaabapsppspspspsps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we need to build a **tf-idf matrix** with the corpus. Let's start with cleaning the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to start with applying a first round of data cleaning (square brackets, lower case)  \n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function\n",
    "    makes text lowercase, \n",
    "    remove text in square brackets, \n",
    "    remove punctuation and \n",
    "    remove words containing numbers.\n",
    "    \"\"\"\n",
    "    text = str(text).lower() # make text lower case\n",
    "    text = re.sub('\\[.*?\\]', '', str(text)) # remove text in square brackets\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', str(text)) # remove punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', '', str(text)) # remove words containing numbers.\n",
    "    return text\n",
    "\n",
    "df['corpus_clean'] = df['corpus'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the reindeer is the emblematic christmas anima...\n",
       "1    the european parliament is split over whether ...\n",
       "2    fisayo soyombo was eating an evening snack in ...\n",
       "3    the european union considers itself as a leade...\n",
       "4    good morning we‚Äôre now exactly two weeks out f...\n",
       "Name: corpus_clean, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus_clean'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the text is cleaned, we're ready to build the tf-idf matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abuse</th>\n",
       "      <th>according</th>\n",
       "      <th>action</th>\n",
       "      <th>africa</th>\n",
       "      <th>african</th>\n",
       "      <th>aid</th>\n",
       "      <th>american</th>\n",
       "      <th>army</th>\n",
       "      <th>article</th>\n",
       "      <th>attack</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053168</td>\n",
       "      <td>0.051550</td>\n",
       "      <td>0.039165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109019</td>\n",
       "      <td>0.092743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.078041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.084885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054005</td>\n",
       "      <td>0.041947</td>\n",
       "      <td>0.102885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059158</td>\n",
       "      <td>0.056128</td>\n",
       "      <td>0.04439</td>\n",
       "      <td>0.039037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045472</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.030039</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abuse  according    action  africa  african  aid  american      army  \\\n",
       "0  0.000000   0.000000  0.000000     0.0      0.0  0.0       0.0  0.000000   \n",
       "1  0.000000   0.000000  0.176560     0.0      0.0  0.0       0.0  0.000000   \n",
       "2  0.000000   0.083860  0.000000     0.0      0.0  0.0       0.0  0.109019   \n",
       "3  0.000000   0.000000  0.111860     0.0      0.0  0.0       0.0  0.000000   \n",
       "4  0.054005   0.041947  0.102885     0.0      0.0  0.0       0.0  0.054533   \n",
       "\n",
       "    article    attack  ...     white     woman    women      work  workers  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000      0.0   \n",
       "1  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000      0.0   \n",
       "2  0.092743  0.000000  ...  0.000000  0.000000  0.00000  0.078041      0.0   \n",
       "3  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.084885      0.0   \n",
       "4  0.000000  0.058097  ...  0.059158  0.056128  0.04439  0.039037      0.0   \n",
       "\n",
       "    working     world      year     years     young  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.053168  0.051550  0.039165  \n",
       "2  0.000000  0.000000  0.061938  0.060053  0.000000  \n",
       "3  0.000000  0.075622  0.000000  0.000000  0.000000  \n",
       "4  0.045472  0.069555  0.061964  0.030039  0.000000  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are going to create a document-term matrix using TfidfVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(max_features = 200, stop_words='english')\n",
    "data_cv = vec.fit_transform(df.corpus_clean)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=vec.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì As you might realised, there exists words (columns) that express the same idea: (woman, women), (work, workers, working). So, we need to use lemmatization or stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stemming(new):\n",
    "    \"\"\"\n",
    "    This function reduces \n",
    "    words to stems.\n",
    "    \"\"\"\n",
    "    tokens = [[token.text for token in sentence] for sentence in nlp(new).sents]\n",
    "    stems = [[stemmer.stem(token) for token in sentence] for sentence in tokens]\n",
    "    stems = \" \".join(str(token) for token in stems)\n",
    "    return stems\n",
    "\n",
    "\n",
    "\n",
    "df['corpus_stem'] = df['corpus_clean'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['sentenc', 'about', 'ai', ',', 'cat', 'and', 'dog', '.']\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming('Sentence about AI, cats and dogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['the', 'reindeer', 'is', 'the', 'emblemat', '...\n",
       "1    ['the', 'european', 'parliament', 'is', 'split...\n",
       "2    ['fisayo', 'soyombo', 'was', 'eat', 'an', 'eve...\n",
       "3    ['the', 'european', 'union', 'consid', 'itself...\n",
       "4    ['good', 'morn', 'we', 're', 'now', 'exact', '...\n",
       "Name: corpus_stem, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus_stem'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the tf-idf matrix again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abus</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aid</th>\n",
       "      <th>alleg</th>\n",
       "      <th>allow</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>water</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>white</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237402</td>\n",
       "      <td>0.164827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.183301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095086</td>\n",
       "      <td>0.044087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091975</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abus    accord       act    action   ad      age  aid     alleg  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000   \n",
       "1  0.000000  0.039308  0.046054  0.183301  0.0  0.00000  0.0  0.000000   \n",
       "2  0.000000  0.080336  0.000000  0.000000  0.0  0.00000  0.0  0.302241   \n",
       "3  0.000000  0.000000  0.000000  0.112173  0.0  0.00000  0.0  0.000000   \n",
       "4  0.091975  0.038702  0.000000  0.090236  0.0  0.04806  0.0  0.048535   \n",
       "\n",
       "      allow  american  ...     water       way      week     white     women  \\\n",
       "0  0.193254       0.0  ...  0.237402  0.164827  0.000000  0.000000  0.000000   \n",
       "1  0.000000       0.0  ...  0.000000  0.000000  0.036177  0.000000  0.000000   \n",
       "2  0.000000       0.0  ...  0.000000  0.000000  0.073936  0.000000  0.000000   \n",
       "3  0.000000       0.0  ...  0.000000  0.091869  0.000000  0.000000  0.000000   \n",
       "4  0.000000       0.0  ...  0.000000  0.000000  0.071237  0.056073  0.042253   \n",
       "\n",
       "       work  worker     world      year     young  \n",
       "0  0.000000     0.0  0.000000  0.000000  0.000000  \n",
       "1  0.000000     0.0  0.000000  0.095086  0.044087  \n",
       "2  0.063040     0.0  0.000000  0.097165  0.000000  \n",
       "3  0.075504     0.0  0.082063  0.000000  0.000000  \n",
       "4  0.060739     0.0  0.066015  0.070214  0.000000  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(max_features = 200, stop_words='english')\n",
    "data_cv = vec.fit_transform(df.corpus_stem)\n",
    "data_dtm_stem = pd.DataFrame(data_cv.toarray(), columns=vec.get_feature_names())\n",
    "data_dtm_stem.index = df.index\n",
    "data_dtm_stem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add the topic of each document by adding the topic column to **<tt> data_dtm_stem <tt>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abus</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aid</th>\n",
       "      <th>alleg</th>\n",
       "      <th>allow</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>white</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.183301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095086</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091975</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abus    accord       act    action   ad      age  aid     alleg  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000   \n",
       "1  0.000000  0.039308  0.046054  0.183301  0.0  0.00000  0.0  0.000000   \n",
       "2  0.000000  0.080336  0.000000  0.000000  0.0  0.00000  0.0  0.302241   \n",
       "3  0.000000  0.000000  0.000000  0.112173  0.0  0.00000  0.0  0.000000   \n",
       "4  0.091975  0.038702  0.000000  0.090236  0.0  0.04806  0.0  0.048535   \n",
       "\n",
       "      allow  american  ...       way      week     white     women      work  \\\n",
       "0  0.193254       0.0  ...  0.164827  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000       0.0  ...  0.000000  0.036177  0.000000  0.000000  0.000000   \n",
       "2  0.000000       0.0  ...  0.000000  0.073936  0.000000  0.000000  0.063040   \n",
       "3  0.000000       0.0  ...  0.091869  0.000000  0.000000  0.000000  0.075504   \n",
       "4  0.000000       0.0  ...  0.000000  0.071237  0.056073  0.042253  0.060739   \n",
       "\n",
       "   worker     world      year     young     topic  \n",
       "0     0.0  0.000000  0.000000  0.000000  climatic  \n",
       "1     0.0  0.000000  0.095086  0.044087  climatic  \n",
       "2     0.0  0.000000  0.097165  0.000000  climatic  \n",
       "3     0.0  0.082063  0.000000  0.000000  climatic  \n",
       "4     0.0  0.066015  0.070214  0.000000  climatic  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml = pd.concat([data_dtm_stem.reset_index(drop=True), df.topic.reset_index(drop=True)], axis=1)\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñüìù **Your turn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a **<tt> data_dtm_lem <tt>** using lemmatization. Is there any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def lemmatizing(new):\n",
    "    \"\"\"\n",
    "    This function reduces \n",
    "    words to lemmas.\n",
    "    \"\"\"\n",
    "    tokens = [[token.lemma_ for token in sentence] for sentence in nlp(new).sents]\n",
    "    lemms = \" \".join(str(token) for token in tokens)\n",
    "    return lemms\n",
    "\n",
    "\n",
    "df['corpus_lem'] = df['corpus_clean'].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['the', 'reindeer', 'be', 'the', 'emblematic',...\n",
       "1    ['the', 'european', 'parliament', 'be', 'split...\n",
       "2    ['fisayo', 'soyombo', 'be', 'eat', 'an', 'even...\n",
       "3    ['the', 'european', 'union', 'consider', '-PRO...\n",
       "4    ['good', 'morning', '-PRON-', 'be', 'now', 'ex...\n",
       "Name: corpus_lem, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus_lem'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abus</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aid</th>\n",
       "      <th>alleg</th>\n",
       "      <th>allow</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>white</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.183301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095086</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091975</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>climatic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abus    accord       act    action   ad      age  aid     alleg  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000   \n",
       "1  0.000000  0.039308  0.046054  0.183301  0.0  0.00000  0.0  0.000000   \n",
       "2  0.000000  0.080336  0.000000  0.000000  0.0  0.00000  0.0  0.302241   \n",
       "3  0.000000  0.000000  0.000000  0.112173  0.0  0.00000  0.0  0.000000   \n",
       "4  0.091975  0.038702  0.000000  0.090236  0.0  0.04806  0.0  0.048535   \n",
       "\n",
       "      allow  american  ...       way      week     white     women      work  \\\n",
       "0  0.193254       0.0  ...  0.164827  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000       0.0  ...  0.000000  0.036177  0.000000  0.000000  0.000000   \n",
       "2  0.000000       0.0  ...  0.000000  0.073936  0.000000  0.000000  0.063040   \n",
       "3  0.000000       0.0  ...  0.091869  0.000000  0.000000  0.000000  0.075504   \n",
       "4  0.000000       0.0  ...  0.000000  0.071237  0.056073  0.042253  0.060739   \n",
       "\n",
       "   worker     world      year     young     topic  \n",
       "0     0.0  0.000000  0.000000  0.000000  climatic  \n",
       "1     0.0  0.000000  0.095086  0.044087  climatic  \n",
       "2     0.0  0.000000  0.097165  0.000000  climatic  \n",
       "3     0.0  0.082063  0.000000  0.000000  climatic  \n",
       "4     0.0  0.066015  0.070214  0.000000  climatic  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a a new tfidf matrix with lemmatizers\n",
    "vec = TfidfVectorizer(max_features = 200, stop_words='english')\n",
    "data_cv = vec.fit_transform(df.corpus_lem)\n",
    "data_dtm_lem = pd.DataFrame(data_cv.toarray(), columns=vec.get_feature_names())\n",
    "data_dtm_lem.index = df.index\n",
    "data_dtm_lem.head()\n",
    "\n",
    "# Add the topic column\n",
    "df_ml_2 = pd.concat([data_dtm_stem.reset_index(drop=True), df.topic.reset_index(drop=True)], axis=1)\n",
    "df_ml_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['abuse', 'accord', 'act', 'action', 'add', 'age', 'aid', 'allow',\n",
       "       'area', 'army', 'article', 'ask', 'attack', 'australia', 'authority',\n",
       "       'away', 'begin', 'believe', 'big', 'black', 'border', 'bring',\n",
       "       'britain', 'british', 'camp', 'campaign', 'case', 'cause', 'centre',\n",
       "       'change', 'child', 'church', 'city', 'claim', 'climate', 'come',\n",
       "       'community', 'company', 'conflict', 'continue', 'control', 'country',\n",
       "       'court', 'crime', 'day', 'deal', 'death', 'die', 'end', 'europe',\n",
       "       'face', 'family', 'far', 'feel', 'fight', 'follow', 'food', 'force',\n",
       "       'foreign', 'girl', 'global', 'good', 'government', 'great', 'group',\n",
       "       'grow', 'guardian', 'happen', 'head', 'health', 'help', 'high',\n",
       "       'history', 'hold', 'home', 'hope', 'house', 'human', 'include',\n",
       "       'increase', 'international', 'issue', 'just', 'kill', 'know', 'labour',\n",
       "       'large', 'later', 'law', 'lead', 'leader', 'leave', 'life', 'like',\n",
       "       'little', 'live', 'local', 'long', 'look', 'lose', 'make', 'man',\n",
       "       'mean', 'meet', 'member', 'migrant', 'military', 'million', 'minister',\n",
       "       'modern', 'money', 'month', 'mother', 'national', 'need', 'new',\n",
       "       'north', 'number', 'office', 'official', 'old', 'open', 'order',\n",
       "       'organisation', 'party', 'past', 'pay', 'people', 'photograph',\n",
       "       'pinterest', 'place', 'plan', 'point', 'police', 'policy', 'political',\n",
       "       'power', 'president', 'problem', 'pron', 'provide', 'public', 'rape',\n",
       "       'read', 'refugee', 'region', 'remain', 'report', 'return', 'right',\n",
       "       'rise', 'risk', 'run', 'say', 'school', 'security', 'send', 'service',\n",
       "       'set', 'sexual', 'slavery', 'soldier', 'south', 'speak', 'start',\n",
       "       'state', 'stop', 'story', 'street', 'supply', 'support', 'talk', 'tell',\n",
       "       'thing', 'think', 'thousand', 'time', 'town', 'trump', 'try', 'turn',\n",
       "       'twitter', 'uk', 'use', 'victim', 'violence', 'visit', 'want', 'war',\n",
       "       'water', 'way', 'week', 'white', 'woman', 'work', 'worker', 'world',\n",
       "       'write', 'year', 'young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_seq_items = 200\n",
    "data_dtm_lem.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['abus', 'accord', 'act', 'action', 'ad', 'age', 'aid', 'alleg', 'allow',\n",
       "       'american', 'ani', 'anoth', 'area', 'arm', 'armi', 'articl', 'ask',\n",
       "       'attack', 'australia', 'author', 'away', 'becaus', 'becom', 'befor',\n",
       "       'believ', 'black', 'border', 'british', 'came', 'camp', 'campaign',\n",
       "       'case', 'centr', 'chang', 'child', 'children', 'church', 'citi',\n",
       "       'claim', 'climat', 'come', 'communiti', 'compani', 'continu', 'countri',\n",
       "       'court', 'crime', 'day', 'death', 'describ', 'develop', 'did', 'die',\n",
       "       'doe', 'dure', 'end', 'everi', 'exploit', 'face', 'famili', 'far',\n",
       "       'fight', 'follow', 'food', 'forc', 'foreign', 'girl', 'global',\n",
       "       'govern', 'group', 'guardian', 'hand', 'happen', 'head', 'health',\n",
       "       'help', 'high', 'home', 'hope', 'hous', 'human', 'includ', 'increas',\n",
       "       'intern', 'investig', 'issu', 'just', 'kill', 'know', 'labour', 'law',\n",
       "       'leader', 'leav', 'left', 'life', 'like', 'live', 'local', 'long',\n",
       "       'look', 'major', 'make', 'man', 'mani', 'member', 'men', 'migrant',\n",
       "       'militari', 'million', 'minist', 'modern', 'month', 'mother', 'nation',\n",
       "       'near', 'need', 'new', 'north', 'number', 'offic', 'offici', 'onli',\n",
       "       'open', 'oper', 'organis', 'parti', 'past', 'peopl', 'photograph',\n",
       "       'pinterest', 'place', 'plan', 'polic', 'polici', 'polit', 'power',\n",
       "       'presid', 'protect', 'protest', 'provid', 'public', 'read', 'recent',\n",
       "       'refuge', 'region', 'remain', 'report', 'respons', 'return', 'right',\n",
       "       'risk', 'rule', 'run', 'said', 'say', 'school', 'secur', 'seen', 'set',\n",
       "       'sever', 'sexual', 'sinc', 'slaveri', 'soldier', 'south', 'start',\n",
       "       'state', 'support', 'taken', 'talk', 'th', 'thing', 'think', 'thousand',\n",
       "       'time', 'told', 'town', 'traffick', 'tri', 'trump', 'turn', 'twitter',\n",
       "       'uk', 'use', 'veri', 'victim', 'villag', 'violenc', 'want', 'war',\n",
       "       'water', 'way', 'week', 'white', 'women', 'work', 'worker', 'world',\n",
       "       'year', 'young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm_stem.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Build machine learning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to classify a ML algorithm to **detect** which new corresponds to climatic change on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we're going to apply a *decision tree* classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåç https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "üåç https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll create a dummy variable that shows which new correponds to climatic topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['topic_climatic_dummy'] = 0\n",
    "\n",
    "df_ml.loc[df['topic'] == 'climatic', 'topic_climatic_dummy'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abus</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aid</th>\n",
       "      <th>alleg</th>\n",
       "      <th>allow</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>white</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "      <th>topic_climatic_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.183301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095086</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091975</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abus    accord       act    action   ad      age  aid     alleg  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000   \n",
       "1  0.000000  0.039308  0.046054  0.183301  0.0  0.00000  0.0  0.000000   \n",
       "2  0.000000  0.080336  0.000000  0.000000  0.0  0.00000  0.0  0.302241   \n",
       "3  0.000000  0.000000  0.000000  0.112173  0.0  0.00000  0.0  0.000000   \n",
       "4  0.091975  0.038702  0.000000  0.090236  0.0  0.04806  0.0  0.048535   \n",
       "\n",
       "      allow  american  ...       way      week     white     women      work  \\\n",
       "0  0.193254       0.0  ...  0.164827  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000       0.0  ...  0.000000  0.036177  0.000000  0.000000  0.000000   \n",
       "2  0.000000       0.0  ...  0.000000  0.073936  0.000000  0.000000  0.063040   \n",
       "3  0.000000       0.0  ...  0.091869  0.000000  0.000000  0.000000  0.075504   \n",
       "4  0.000000       0.0  ...  0.000000  0.071237  0.056073  0.042253  0.060739   \n",
       "\n",
       "   worker     world      year     young  topic_climatic_dummy  \n",
       "0     0.0  0.000000  0.000000  0.000000                     1  \n",
       "1     0.0  0.000000  0.095086  0.044087                     1  \n",
       "2     0.0  0.000000  0.097165  0.000000                     1  \n",
       "3     0.0  0.082063  0.000000  0.000000                     1  \n",
       "4     0.0  0.066015  0.070214  0.000000                     1  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abus</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aid</th>\n",
       "      <th>alleg</th>\n",
       "      <th>allow</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>white</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "      <th>topic_climatic_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161357</td>\n",
       "      <td>0.675497</td>\n",
       "      <td>0.155364</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.073876</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.041636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011705</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.135036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.554426</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.058591</td>\n",
       "      <td>0.104996</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>0.056443</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>0.031122</td>\n",
       "      <td>0.026191</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065691</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.094735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087524</td>\n",
       "      <td>0.036157</td>\n",
       "      <td>0.056921</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>0.082210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078182</td>\n",
       "      <td>0.079195</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          abus    accord       act    action        ad       age  aid  \\\n",
       "1629  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "1630  0.000000  0.024749  0.000000  0.043278  0.000000  0.046100  0.0   \n",
       "1631  0.000000  0.009333  0.010935  0.021761  0.000000  0.000000  0.0   \n",
       "1632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "1633  0.031122  0.026191  0.015343  0.000000  0.014813  0.016262  0.0   \n",
       "\n",
       "         alleg     allow  american  ...       way      week     white  \\\n",
       "1629  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1630  0.000000  0.000000  0.017903  ...  0.141777  0.000000  0.161357   \n",
       "1631  0.011705  0.010448  0.135036  ...  0.017822  0.017180  0.554426   \n",
       "1632  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1633  0.065691  0.014660  0.094735  ...  0.087524  0.036157  0.056921   \n",
       "\n",
       "         women      work    worker     world      year     young  \\\n",
       "1629  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1630  0.675497  0.155364  0.015467  0.073876  0.014967  0.041636   \n",
       "1631  0.040759  0.058591  0.104996  0.015920  0.056443  0.062807   \n",
       "1632  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1633  0.014297  0.082210  0.000000  0.078182  0.079195  0.014688   \n",
       "\n",
       "      topic_climatic_dummy  \n",
       "1629                     0  \n",
       "1630                     0  \n",
       "1631                     0  \n",
       "1632                     0  \n",
       "1633                     0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['topic'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7ccf100b7497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/env35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/env35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env35/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4962\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4963\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4964\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4965\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4966\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['topic'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_ml = df_ml.drop(['topic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abus</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>ad</th>\n",
       "      <th>age</th>\n",
       "      <th>aid</th>\n",
       "      <th>alleg</th>\n",
       "      <th>allow</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>week</th>\n",
       "      <th>white</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>young</th>\n",
       "      <th>topic_climatic_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039308</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.183301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095086</td>\n",
       "      <td>0.044087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091975</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>0.042253</td>\n",
       "      <td>0.060739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abus    accord       act    action   ad      age  aid     alleg  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.00000  0.0  0.000000   \n",
       "1  0.000000  0.039308  0.046054  0.183301  0.0  0.00000  0.0  0.000000   \n",
       "2  0.000000  0.080336  0.000000  0.000000  0.0  0.00000  0.0  0.302241   \n",
       "3  0.000000  0.000000  0.000000  0.112173  0.0  0.00000  0.0  0.000000   \n",
       "4  0.091975  0.038702  0.000000  0.090236  0.0  0.04806  0.0  0.048535   \n",
       "\n",
       "      allow  american  ...       way      week     white     women      work  \\\n",
       "0  0.193254       0.0  ...  0.164827  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000       0.0  ...  0.000000  0.036177  0.000000  0.000000  0.000000   \n",
       "2  0.000000       0.0  ...  0.000000  0.073936  0.000000  0.000000  0.063040   \n",
       "3  0.000000       0.0  ...  0.091869  0.000000  0.000000  0.000000  0.075504   \n",
       "4  0.000000       0.0  ...  0.000000  0.071237  0.056073  0.042253  0.060739   \n",
       "\n",
       "   worker     world      year     young  topic_climatic_dummy  \n",
       "0     0.0  0.000000  0.000000  0.000000                     1  \n",
       "1     0.0  0.000000  0.095086  0.044087                     1  \n",
       "2     0.0  0.000000  0.097165  0.000000                     1  \n",
       "3     0.0  0.082063  0.000000  0.000000                     1  \n",
       "4     0.0  0.066015  0.070214  0.000000                     1  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset into training and testing.  **<tt> Sklearn <tt>** has already a function thas does it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, topic_train, topic_test = train_test_split(df_ml.iloc[:,:-1], df_ml.iloc[:,-1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's train our classifier with our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=4, random_state=15)\n",
    "dt = dt.fit(df_train, topic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test the performance of the classifier with our testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975925925925926"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "topic_pred = dt.predict(df_test)\n",
    "score = accuracy_score(topic_test, topic_pred)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow! Our decision tree correclty classifies 97.59% of news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåç https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/avaldivia/env37/lib/python3.7/site-packages (0.16)\n",
      "\u001b[33mWARNING: You are using pip version 20.2b1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/avaldivia/env37/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "!pip install graphviz\n",
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                      feature_names=df_train.columns,    \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"938pt\" height=\"477pt\"\n",
       " viewBox=\"0.00 0.00 937.50 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-473 933.5,-473 933.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<path fill=\"#e99254\" stroke=\"black\" d=\"M669.5,-469C669.5,-469 568.5,-469 568.5,-469 562.5,-469 556.5,-463 556.5,-457 556.5,-457 556.5,-413 556.5,-413 556.5,-407 562.5,-401 568.5,-401 568.5,-401 669.5,-401 669.5,-401 675.5,-401 681.5,-407 681.5,-413 681.5,-413 681.5,-457 681.5,-457 681.5,-463 675.5,-469 669.5,-469\"/>\n",
       "<text text-anchor=\"start\" x=\"576\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">climat ‚â§ 0.156</text>\n",
       "<text text-anchor=\"start\" x=\"583.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.214</text>\n",
       "<text text-anchor=\"start\" x=\"570.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1094</text>\n",
       "<text text-anchor=\"start\" x=\"564.5\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [961, 133]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<path fill=\"#e6843d\" stroke=\"black\" d=\"M525.5,-365C525.5,-365 432.5,-365 432.5,-365 426.5,-365 420.5,-359 420.5,-353 420.5,-353 420.5,-309 420.5,-309 420.5,-303 426.5,-297 432.5,-297 432.5,-297 525.5,-297 525.5,-297 531.5,-297 537.5,-303 537.5,-309 537.5,-309 537.5,-353 537.5,-353 537.5,-359 531.5,-365 525.5,-365\"/>\n",
       "<text text-anchor=\"start\" x=\"436\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">climat ‚â§ 0.042</text>\n",
       "<text text-anchor=\"start\" x=\"443.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.042</text>\n",
       "<text text-anchor=\"start\" x=\"434\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 975</text>\n",
       "<text text-anchor=\"start\" x=\"428.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [954, 21]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M573.546,-400.884C560.587,-391.442 546.342,-381.064 532.93,-371.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"534.848,-368.359 524.705,-365.299 530.726,-374.017 534.848,-368.359\"/>\n",
       "<text text-anchor=\"middle\" x=\"528.583\" y=\"-386.297\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\n",
       "<path fill=\"#45a3e7\" stroke=\"black\" d=\"M803,-365C803,-365 717,-365 717,-365 711,-365 705,-359 705,-353 705,-353 705,-309 705,-309 705,-303 711,-297 717,-297 717,-297 803,-297 803,-297 809,-297 815,-303 815,-309 815,-309 815,-353 815,-353 815,-359 809,-365 803,-365\"/>\n",
       "<text text-anchor=\"start\" x=\"713\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">increas ‚â§ 0.336</text>\n",
       "<text text-anchor=\"start\" x=\"724.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.111</text>\n",
       "<text text-anchor=\"start\" x=\"715\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 119</text>\n",
       "<text text-anchor=\"start\" x=\"713\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 112]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>0&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M664.779,-400.884C677.831,-391.442 692.177,-381.064 705.685,-371.292\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"707.918,-373.996 713.969,-365.299 703.815,-368.325 707.918,-373.996\"/>\n",
       "<text text-anchor=\"middle\" x=\"710.007\" y=\"-386.283\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<path fill=\"#e5823a\" stroke=\"black\" d=\"M339,-261C339,-261 253,-261 253,-261 247,-261 241,-255 241,-249 241,-249 241,-205 241,-205 241,-199 247,-193 253,-193 253,-193 339,-193 339,-193 345,-193 351,-199 351,-205 351,-205 351,-249 351,-249 351,-255 345,-261 339,-261\"/>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">becaus ‚â§ 0.335</text>\n",
       "<text text-anchor=\"start\" x=\"260.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.015</text>\n",
       "<text text-anchor=\"start\" x=\"251\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 933</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [926, 7]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.343,-297.306C401.123,-286.593 379.674,-274.638 360.075,-263.714\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.653,-260.587 351.214,-258.775 358.245,-266.701 361.653,-260.587\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<path fill=\"#f2c09c\" stroke=\"black\" d=\"M522,-261C522,-261 436,-261 436,-261 430,-261 424,-255 424,-249 424,-249 424,-205 424,-205 424,-199 430,-193 436,-193 436,-193 522,-193 522,-193 528,-193 534,-199 534,-205 534,-205 534,-249 534,-249 534,-255 528,-261 522,-261\"/>\n",
       "<text text-anchor=\"start\" x=\"435.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">power ‚â§ 0.062</text>\n",
       "<text text-anchor=\"start\" x=\"443.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"438\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n",
       "<text text-anchor=\"start\" x=\"432\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 14]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>1&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M479,-296.884C479,-288.778 479,-279.982 479,-271.472\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"482.5,-271.299 479,-261.299 475.5,-271.299 482.5,-271.299\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<path fill=\"#e5823a\" stroke=\"black\" d=\"M218,-157C218,-157 128,-157 128,-157 122,-157 116,-151 116,-145 116,-145 116,-101 116,-101 116,-95 122,-89 128,-89 128,-89 218,-89 218,-89 224,-89 230,-95 230,-101 230,-101 230,-145 230,-145 230,-151 224,-157 218,-157\"/>\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">respons ‚â§ 0.333</text>\n",
       "<text text-anchor=\"start\" x=\"137.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.013</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 932</text>\n",
       "<text text-anchor=\"start\" x=\"126\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [926, 6]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M256.065,-192.884C244.895,-183.62 232.637,-173.455 221.049,-163.845\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.087,-160.989 213.155,-157.299 218.619,-166.377 223.087,-160.989\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M331.5,-149.5C331.5,-149.5 260.5,-149.5 260.5,-149.5 254.5,-149.5 248.5,-143.5 248.5,-137.5 248.5,-137.5 248.5,-108.5 248.5,-108.5 248.5,-102.5 254.5,-96.5 260.5,-96.5 260.5,-96.5 331.5,-96.5 331.5,-96.5 337.5,-96.5 343.5,-102.5 343.5,-108.5 343.5,-108.5 343.5,-137.5 343.5,-137.5 343.5,-143.5 337.5,-149.5 331.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"268\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"258.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"256.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296,-192.884C296,-182.326 296,-170.597 296,-159.854\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"299.5,-159.52 296,-149.52 292.5,-159.52 299.5,-159.52\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<path fill=\"#e5823a\" stroke=\"black\" d=\"M98,-53C98,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 98,-0 98,-0 104,-0 110,-6 110,-12 110,-12 110,-41 110,-41 110,-47 104,-53 98,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.011</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 931</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [926, 5]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.729,-88.9485C119.85,-79.4346 106.912,-69.074 95.1044,-59.6175\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"97.1302,-56.7558 87.1368,-53.2367 92.7545,-62.2196 97.1302,-56.7558\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M211.5,-53C211.5,-53 140.5,-53 140.5,-53 134.5,-53 128.5,-47 128.5,-41 128.5,-41 128.5,-12 128.5,-12 128.5,-6 134.5,-0 140.5,-0 140.5,-0 211.5,-0 211.5,-0 217.5,-0 223.5,-6 223.5,-12 223.5,-12 223.5,-41 223.5,-41 223.5,-47 217.5,-53 211.5,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"138.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"136.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.049,-88.9485C174.311,-80.7153 174.592,-71.848 174.858,-63.4814\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.364,-63.3428 175.183,-53.2367 171.367,-63.1206 178.364,-63.3428\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<path fill=\"#eca26c\" stroke=\"black\" d=\"M452,-157C452,-157 374,-157 374,-157 368,-157 362,-151 362,-145 362,-145 362,-101 362,-101 362,-95 368,-89 374,-89 374,-89 452,-89 452,-89 458,-89 464,-95 464,-101 464,-101 464,-145 464,-145 464,-151 458,-157 452,-157\"/>\n",
       "<text text-anchor=\"start\" x=\"379\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">fight ‚â§ 0.06</text>\n",
       "<text text-anchor=\"start\" x=\"377.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.327</text>\n",
       "<text text-anchor=\"start\" x=\"372\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n",
       "<text text-anchor=\"start\" x=\"370\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [27, 7]</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M457.572,-192.884C451.981,-184.243 445.883,-174.819 440.042,-165.793\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"442.918,-163.794 434.547,-157.299 437.041,-167.596 442.918,-163.794\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\n",
       "<path fill=\"#55abe9\" stroke=\"black\" d=\"M573.5,-157C573.5,-157 494.5,-157 494.5,-157 488.5,-157 482.5,-151 482.5,-145 482.5,-145 482.5,-101 482.5,-101 482.5,-95 488.5,-89 494.5,-89 494.5,-89 573.5,-89 573.5,-89 579.5,-89 585.5,-95 585.5,-101 585.5,-101 585.5,-145 585.5,-145 585.5,-151 579.5,-157 573.5,-157\"/>\n",
       "<text text-anchor=\"start\" x=\"490.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">chang ‚â§ 0.096</text>\n",
       "<text text-anchor=\"start\" x=\"498.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n",
       "<text text-anchor=\"start\" x=\"496.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n",
       "<text text-anchor=\"start\" x=\"494.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 7]</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M496.857,-192.884C501.42,-184.422 506.388,-175.207 511.163,-166.352\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"514.379,-167.762 516.044,-157.299 508.218,-164.44 514.379,-167.762\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<path fill=\"#e99456\" stroke=\"black\" d=\"M335,-53C335,-53 257,-53 257,-53 251,-53 245,-47 245,-41 245,-41 245,-12 245,-12 245,-6 251,-0 257,-0 257,-0 335,-0 335,-0 341,-0 347,-6 347,-12 347,-12 347,-41 347,-41 347,-47 341,-53 335,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"260.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.225</text>\n",
       "<text text-anchor=\"start\" x=\"255\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n",
       "<text text-anchor=\"start\" x=\"253\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [27, 4]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.079,-88.9485C360.3,-79.4346 347.473,-69.074 335.765,-59.6175\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"337.843,-56.7973 327.864,-53.2367 333.445,-62.2429 337.843,-56.7973\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M448.5,-53C448.5,-53 377.5,-53 377.5,-53 371.5,-53 365.5,-47 365.5,-41 365.5,-41 365.5,-12 365.5,-12 365.5,-6 371.5,-0 377.5,-0 377.5,-0 448.5,-0 448.5,-0 454.5,-0 460.5,-6 460.5,-12 460.5,-12 460.5,-41 460.5,-41 460.5,-47 454.5,-53 448.5,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"385\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"375.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"373.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M413,-88.9485C413,-80.7153 413,-71.848 413,-63.4814\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"416.5,-63.2367 413,-53.2367 409.5,-63.2367 416.5,-63.2367\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M561.5,-53C561.5,-53 490.5,-53 490.5,-53 484.5,-53 478.5,-47 478.5,-41 478.5,-41 478.5,-12 478.5,-12 478.5,-6 484.5,-0 490.5,-0 490.5,-0 561.5,-0 561.5,-0 567.5,-0 573.5,-6 573.5,-12 573.5,-12 573.5,-41 573.5,-41 573.5,-47 567.5,-53 561.5,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"498\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"488.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n",
       "<text text-anchor=\"start\" x=\"486.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 7]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M531.202,-88.9485C530.497,-80.6238 529.738,-71.6509 529.022,-63.2027\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"532.51,-62.9058 528.179,-53.2367 525.535,-63.4963 532.51,-62.9058\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M674.5,-53C674.5,-53 603.5,-53 603.5,-53 597.5,-53 591.5,-47 591.5,-41 591.5,-41 591.5,-12 591.5,-12 591.5,-6 597.5,-0 603.5,-0 603.5,-0 674.5,-0 674.5,-0 680.5,-0 686.5,-6 686.5,-12 686.5,-12 686.5,-41 686.5,-41 686.5,-47 680.5,-53 674.5,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"611\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"601.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"599.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>11&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M570.724,-88.9485C581.092,-79.6175 592.364,-69.4722 602.707,-60.1641\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"605.312,-62.5279 610.404,-53.2367 600.629,-57.3248 605.312,-62.5279\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\n",
       "<path fill=\"#42a1e6\" stroke=\"black\" d=\"M804.5,-261C804.5,-261 715.5,-261 715.5,-261 709.5,-261 703.5,-255 703.5,-249 703.5,-249 703.5,-205 703.5,-205 703.5,-199 709.5,-193 715.5,-193 715.5,-193 804.5,-193 804.5,-193 810.5,-193 816.5,-199 816.5,-205 816.5,-205 816.5,-249 816.5,-249 816.5,-255 810.5,-261 804.5,-261\"/>\n",
       "<text text-anchor=\"start\" x=\"711.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">modern ‚â§ 0.101</text>\n",
       "<text text-anchor=\"start\" x=\"724.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.082</text>\n",
       "<text text-anchor=\"start\" x=\"715\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 117</text>\n",
       "<text text-anchor=\"start\" x=\"713\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 112]</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M760,-296.884C760,-288.778 760,-279.982 760,-271.472\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"763.5,-271.299 760,-261.299 756.5,-271.299 763.5,-271.299\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\"><title>20</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M917.5,-253.5C917.5,-253.5 846.5,-253.5 846.5,-253.5 840.5,-253.5 834.5,-247.5 834.5,-241.5 834.5,-241.5 834.5,-212.5 834.5,-212.5 834.5,-206.5 840.5,-200.5 846.5,-200.5 846.5,-200.5 917.5,-200.5 917.5,-200.5 923.5,-200.5 929.5,-206.5 929.5,-212.5 929.5,-212.5 929.5,-241.5 929.5,-241.5 929.5,-247.5 923.5,-253.5 917.5,-253.5\"/>\n",
       "<text text-anchor=\"start\" x=\"854\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"844.5\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"842.5\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>14&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M799.61,-296.884C813.685,-285.116 829.5,-271.894 843.482,-260.203\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"846.049,-262.619 851.476,-253.52 841.559,-257.249 846.049,-262.619\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\n",
       "<path fill=\"#3ea0e6\" stroke=\"black\" d=\"M803,-157C803,-157 717,-157 717,-157 711,-157 705,-151 705,-145 705,-145 705,-101 705,-101 705,-95 711,-89 717,-89 717,-89 803,-89 803,-89 809,-89 815,-95 815,-101 815,-101 815,-145 815,-145 815,-151 809,-157 803,-157\"/>\n",
       "<text text-anchor=\"start\" x=\"720.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">minist ‚â§ 0.39</text>\n",
       "<text text-anchor=\"start\" x=\"724.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.051</text>\n",
       "<text text-anchor=\"start\" x=\"715\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 115</text>\n",
       "<text text-anchor=\"start\" x=\"713\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 112]</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M760,-192.884C760,-184.778 760,-175.982 760,-167.472\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"763.5,-167.299 760,-157.299 756.5,-167.299 763.5,-167.299\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M916.5,-149.5C916.5,-149.5 845.5,-149.5 845.5,-149.5 839.5,-149.5 833.5,-143.5 833.5,-137.5 833.5,-137.5 833.5,-108.5 833.5,-108.5 833.5,-102.5 839.5,-96.5 845.5,-96.5 845.5,-96.5 916.5,-96.5 916.5,-96.5 922.5,-96.5 928.5,-102.5 928.5,-108.5 928.5,-108.5 928.5,-137.5 928.5,-137.5 928.5,-143.5 922.5,-149.5 916.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"853\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"843.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"841.5\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>15&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M799.285,-192.884C813.245,-181.116 828.93,-167.894 842.798,-156.203\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"845.336,-158.641 850.726,-149.52 840.825,-153.289 845.336,-158.641\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\n",
       "<path fill=\"#3d9fe5\" stroke=\"black\" d=\"M803,-53C803,-53 717,-53 717,-53 711,-53 705,-47 705,-41 705,-41 705,-12 705,-12 705,-6 711,-0 717,-0 717,-0 803,-0 803,-0 809,-0 815,-6 815,-12 815,-12 815,-41 815,-41 815,-47 809,-53 803,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"724.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.034</text>\n",
       "<text text-anchor=\"start\" x=\"715\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 114</text>\n",
       "<text text-anchor=\"start\" x=\"713\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 112]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M760,-88.9485C760,-80.7153 760,-71.848 760,-63.4814\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"763.5,-63.2367 760,-53.2367 756.5,-63.2367 763.5,-63.2367\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M916.5,-53C916.5,-53 845.5,-53 845.5,-53 839.5,-53 833.5,-47 833.5,-41 833.5,-41 833.5,-12 833.5,-12 833.5,-6 839.5,-0 845.5,-0 845.5,-0 916.5,-0 916.5,-0 922.5,-0 928.5,-6 928.5,-12 928.5,-12 928.5,-41 928.5,-41 928.5,-47 922.5,-53 916.5,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"853\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"843.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"841.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>16&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M802.32,-88.9485C814.502,-79.4346 827.768,-69.074 839.876,-59.6175\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"842.319,-62.1504 848.046,-53.2367 838.011,-56.6335 842.319,-62.1504\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f8306602a58>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñüìù **Your turn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to classify *child _soldiers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['topic_child_soldiers_dummy'] = 0\n",
    "\n",
    "df_ml.loc[df['topic'] == 'child soldiers', 'topic_child_soldiers_dummy'] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
