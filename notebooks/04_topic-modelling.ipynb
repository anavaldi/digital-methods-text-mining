{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Topic modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the basics of topic modelling. \n",
    "You'll learn how identify topics in documents using the tf-idf matrix and ML classifier.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend of symbols:\n",
    "\n",
    "- ü§ì: Tips\n",
    "\n",
    "- ü§ñüìù: Your turn\n",
    "\n",
    "- ‚ùì: Question\n",
    "\n",
    "- üí´: Extra exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Tf-idf matrix + ML classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll learn how to do topic modelling based on bag of words and ML classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Build tf-idf matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the news dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>media</th>\n",
       "      <th>corpus</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>The reindeer is the emblematic Christmas anima...</td>\n",
       "      <td>Weatherwatch: reindeer adapted to snow but not...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/dec/23/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>The European parliament is split over whether ...</td>\n",
       "      <td>European parliament split on declaring climate...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/nov/26/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Fisayo Soyombo was eating an evening snack in ...</td>\n",
       "      <td>‚ÄòClimate of fear‚Äô: Nigeria intensifies crackdo...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/nov/14/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>The European Union considers itself as a leade...</td>\n",
       "      <td>EU's soaring climate rhetoric not always match...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/dec/11/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climatic</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>Good morning, we‚Äôre now exactly two weeks out ...</td>\n",
       "      <td>Thursday briefing: Political climate too hot f...</td>\n",
       "      <td>https://www.theguardian.com/world/2019/nov/28/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic         media                                             corpus  \\\n",
       "0  climatic  The Guardian  The reindeer is the emblematic Christmas anima...   \n",
       "1  climatic  The Guardian  The European parliament is split over whether ...   \n",
       "2  climatic  The Guardian  Fisayo Soyombo was eating an evening snack in ...   \n",
       "3  climatic  The Guardian  The European Union considers itself as a leade...   \n",
       "4  climatic  The Guardian  Good morning, we‚Äôre now exactly two weeks out ...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Weatherwatch: reindeer adapted to snow but not...   \n",
       "1  European parliament split on declaring climate...   \n",
       "2  ‚ÄòClimate of fear‚Äô: Nigeria intensifies crackdo...   \n",
       "3  EU's soaring climate rhetoric not always match...   \n",
       "4  Thursday briefing: Political climate too hot f...   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.theguardian.com/world/2019/dec/23/...  \n",
       "1  https://www.theguardian.com/world/2019/nov/26/...  \n",
       "2  https://www.theguardian.com/world/2019/nov/14/...  \n",
       "3  https://www.theguardian.com/world/2019/dec/11/...  \n",
       "4  https://www.theguardian.com/world/2019/nov/28/...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we need to build a **tf-idf matrix** with the corpus. Let's start with cleaning the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to start with applying a first round of data cleaning (square brackets, lower case)  \n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function\n",
    "    makes text lowercase, \n",
    "    remove text in square brackets, \n",
    "    remove punctuation and \n",
    "    remove words containing numbers.\n",
    "    \"\"\"\n",
    "    text = str(text).lower() # make text lower case\n",
    "    text = re.sub('\\[.*?\\]', '', str(text)) # remove text in square brackets\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', str(text)) # remove punctuation\n",
    "    text = re.sub('\\w*\\d\\w*', '', str(text)) # remove words containing numbers.\n",
    "    return text\n",
    "\n",
    "df['corpus_clean'] = df['corpus'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the reindeer is the emblematic christmas anima...\n",
       "1    the european parliament is split over whether ...\n",
       "2    fisayo soyombo was eating an evening snack in ...\n",
       "3    the european union considers itself as a leade...\n",
       "4    good morning we‚Äôre now exactly two weeks out f...\n",
       "Name: corpus_clean, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus_clean'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the text is cleaned, we're ready to build the tf-idf matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abuse</th>\n",
       "      <th>according</th>\n",
       "      <th>action</th>\n",
       "      <th>africa</th>\n",
       "      <th>african</th>\n",
       "      <th>aid</th>\n",
       "      <th>american</th>\n",
       "      <th>army</th>\n",
       "      <th>article</th>\n",
       "      <th>attack</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>work</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053168</td>\n",
       "      <td>0.051550</td>\n",
       "      <td>0.039165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109019</td>\n",
       "      <td>0.092743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.078041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.084885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054005</td>\n",
       "      <td>0.041947</td>\n",
       "      <td>0.102885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059158</td>\n",
       "      <td>0.056128</td>\n",
       "      <td>0.04439</td>\n",
       "      <td>0.039037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045472</td>\n",
       "      <td>0.069555</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.030039</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abuse  according    action  africa  african  aid  american      army  \\\n",
       "0  0.000000   0.000000  0.000000     0.0      0.0  0.0       0.0  0.000000   \n",
       "1  0.000000   0.000000  0.176560     0.0      0.0  0.0       0.0  0.000000   \n",
       "2  0.000000   0.083860  0.000000     0.0      0.0  0.0       0.0  0.109019   \n",
       "3  0.000000   0.000000  0.111860     0.0      0.0  0.0       0.0  0.000000   \n",
       "4  0.054005   0.041947  0.102885     0.0      0.0  0.0       0.0  0.054533   \n",
       "\n",
       "    article    attack  ...     white     woman    women      work  workers  \\\n",
       "0  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000      0.0   \n",
       "1  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.000000      0.0   \n",
       "2  0.092743  0.000000  ...  0.000000  0.000000  0.00000  0.078041      0.0   \n",
       "3  0.000000  0.000000  ...  0.000000  0.000000  0.00000  0.084885      0.0   \n",
       "4  0.000000  0.058097  ...  0.059158  0.056128  0.04439  0.039037      0.0   \n",
       "\n",
       "    working     world      year     years     young  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.053168  0.051550  0.039165  \n",
       "2  0.000000  0.000000  0.061938  0.060053  0.000000  \n",
       "3  0.000000  0.075622  0.000000  0.000000  0.000000  \n",
       "4  0.045472  0.069555  0.061964  0.030039  0.000000  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are going to create a document-term matrix using TfidfVectorizer, and exclude common English stop words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(max_features = 200, stop_words='english')\n",
    "data_cv = vec.fit_transform(df.corpus_clean)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=vec.get_feature_names())\n",
    "data_dtm.index = df.index\n",
    "data_dtm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì As you might realised, there exists words (columns) that express the same idea: (woman, women), (work, workers, working). So, we need to use lemmatization or stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stemming(new):\n",
    "    \"\"\"\n",
    "    This function reduces \n",
    "    words to stems.\n",
    "    \"\"\"\n",
    "    tokens = [[token.text for token in sentence] for sentence in nlp(new).sents]\n",
    "    stems = [[stemmer.stem(token) for token in sentence] for sentence in tokens]\n",
    "    stems = \" \".join(str(token) for token in stems)\n",
    "    return stems\n",
    "\n",
    "df['corpus_stem'] = df['corpus_clean'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corpus_stem'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the tf-idf matrix again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = vec.fit_transform(df.corpus_stem)\n",
    "data_dtm_stem = pd.DataFrame(data_cv.toarray(), columns=vec.get_feature_names())\n",
    "data_dtm_stem.index = df.index\n",
    "data_dtm_stem.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add the topic of each document by adding the topic column to **<tt> data_dtm_stem <tt>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = pd.concat([data_dtm_stem.reset_index(drop=True), df.topic.reset_index(drop=True)], axis=1)\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñüìù **Your turn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a **<tt> data_dtm_lem <tt>** using lemmatization. Is there any difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Build machine learning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to classify a ML algorithm to **detect** which new corresponds to climatic change on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we're going to apply a *decision tree* classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåç https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "üåç https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll create a dummy variable that shows which new correponds to climatic topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['topic_climatic_dummy'] = 0\n",
    "\n",
    "df_ml.loc[df['topic'] == 'climatic', 'topic_climatic_dummy'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset into training and testing.  **<tt> Sklearn <tt>** has already a function thas does it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, topic_train, topic_test = train_test_split(df_ml.iloc[:,:-2], df_ml.iloc[:,-1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's train our classifier with our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=4)\n",
    "dt = dt.fit(df_train, topic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test the performance of the classifier with our testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "topic_pred = dt.predict(df_test)\n",
    "score = accuracy_score(topic_test, topic_pred)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow! Our decision tree correclty classifies 96.85% of news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåç https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                      feature_names=df_train.columns,    \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñüìù **Your turn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classifier to classify *child _soldiers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['topic_child_soldiers_dummy'] = 0\n",
    "\n",
    "df_ml.loc[df['topic'] == 'child soldiers', 'topic_child_soldiers_dummy'] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
