{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the basics of analysing words. \n",
    "You'll learn how to preprocess and represent text.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend of symbols:\n",
    "\n",
    "- ü§ì: Tips\n",
    "\n",
    "- ü§ñüìù: Your turn\n",
    "\n",
    "- ‚ùì: Question\n",
    "\n",
    "- üí´: Extra exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Word vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll learn how to transform words into vectors. Let's start with one-hot encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library **<tt> sklearn <tt>** has a function that transforms categorical features to one-hot vectors:\n",
    "    \n",
    "üåç https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html \n",
    "\n",
    "üåç https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the functions we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Can I eat the Pizza\".lower()\n",
    "sent2 = \"You can eat the Pizza\".lower()\n",
    "\n",
    "doc1 = sent1.split()\n",
    "doc2 = sent2.split()\n",
    "\n",
    "doc1_array = array(doc1)\n",
    "doc2_array = array(doc2)\n",
    "\n",
    "doc3 = doc1+doc2\n",
    "data = list(doc3)\n",
    "\n",
    "values = array(data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What does this code do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will transform words to numbers based on its position. To do so, we will use the **<tt> LabelEncoder() <tt>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows the order of words in the matrix\n",
    "list(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñüìù **Your turn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the news dataset and calculate the onehot encoding of the first new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Word embeddings (word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a word2vec model in Python is scarily easy with **<tt> gensim <tt>**.\n",
    "    \n",
    "üåç https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train the word2vec model taking a look to the parameters:\n",
    "\n",
    "üåç https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will prepare the data. To do so, we need to transform every sentence in a list within a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Can I eat the Pizza\".lower()\n",
    "sent2 = \"You can eat the Pizza\".lower()\n",
    "\n",
    "doc1 = sent1.split()\n",
    "doc2 = sent2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = [doc1, doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(doc3, size=300, window=3, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can analyse the vocabulary of this word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analyse the embeddings by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['pizza']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using word2vec, we can analyse similarities across words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['pizza',], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(negative=['pizza',], topn=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And relations between words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.similarity('pizza', 'eat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§ì Note that this model doesn't contain a lot of text, so it doesn't make sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñüìù **Your turn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a word2vec embedding with the news corpus and extract the top 10 most similar words of *ultraviolet*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Help to prepare the input for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'reindeer', 'is', 'the', 'emblematic', 'christmas', 'animal', 'and,', 'while', 'not', 'exactly', 'magical,', 'it', 'is', 'among', 'the', 'best', 'adapted', 'to', 'snowy', 'conditions.for', 'a', 'start,', 'a', 'reindeer‚Äôs', 'feet', 'have', 'four', 'toes', 'with', 'dewclaws', 'that', 'spread', 'out', 'to', 'distribute', 'its', 'weight', 'like', 'snowshoes,', 'and', 'are', 'equipped', 'with', 'sharp', 'hooves', 'for', 'digging', 'in', 'snow.a', 'reindeer‚Äôs', 'nose', 'warms', 'the', 'air', 'on', 'its', 'way', 'to', 'the', 'lungs,', 'cooling', 'it', 'again', 'before', 'it', 'is', 'exhaled.', 'as', 'well', 'as', 'retaining', 'heat,', 'this', 'helps', 'prevent', 'water', 'from', 'being', 'lost', 'as', 'vapour.', 'this', 'is', 'why', 'reindeer', 'breath', 'does', 'not', 'steam', 'like', 'human', 'and', 'horse', 'breath.a', 'reindeer‚Äôs', 'thick', 'double-layered', 'coat', 'is', 'so', 'efficient', 'that', 'it', 'is', 'more', 'likely', 'to', 'overheat', 'than', 'get', 'too', 'cold,', 'especially', 'when', 'running.', 'when', 'this', 'happens,', 'reindeer', 'pant', 'like', 'dogs', 'to', 'cool', 'down,', 'bypassing', 'the', 'nasal', 'heat', 'exchanger.snowfields', 'may', 'be', 'featureless', 'to', 'human', 'eyes,', 'but', 'reindeer', 'are', 'sensitive', 'to', 'ultraviolet', 'light,', 'an', 'evolutionary', 'development', 'that', 'only', 'occurred', 'after', 'the', 'animals', 'moved', 'to', 'arctic', 'regions.', 'snow', 'reflects', 'ultraviolet,', 'so', 'this', 'ultravision', 'allows', 'reindeer', 'to', 'spot', 'anything', 'lying', 'on', 'it,', 'in', 'particular', 'lichen,', 'which', 'they', 'eat,', 'and', 'traces', 'of', 'urine', 'showing', 'where', 'other', 'reindeer', 'have', 'passed.but', 'while', 'reindeer', 'thrive', 'in', 'christmas-card', 'weather,', 'they', 'are', 'increasingly', 'challenged', 'by', 'climate', 'change', 'and', 'the', 'freeze-thaw', 'conditions', 'that', 'produce', 'poor', 'grazing.']\n"
     ]
    }
   ],
   "source": [
    "# This is a loop that iterates over the dataframe\n",
    "news_vec = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    sent = row['corpus'].lower()\n",
    "    sent = sent.split()\n",
    "    news_vec.append(sent)    \n",
    " \n",
    "# Print the first element of the list:\n",
    "print(news_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üí´ Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract the most similiar word to *climate*.\n",
    "- Calculate the similarity between *climate* and *weather*.\n",
    "- Calculate the most similar word to *huamanitarian* + *climate* - *droguth*.\n",
    "\n",
    "Does make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Word preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìï Hovy, D. (2020). Text Analysis in Python for Social Scientists: Discovery and Exploration. Cambridge University Press.\n",
    "\n",
    "üåç https://medium.com/zero-equals-false/one-hot-encoding-129ccc293cda\n",
    "\n",
    "üåç https://markroxor.github.io/gensim/static/notebooks/word2vec.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
